# -*- coding: utf-8 -*-
"""Copy of Practice.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1F59shT4VOKSFNErOE2tf9DOqkGtf9pZF

## Training

This section contains implementation specifics of building a CNN based image classifier using the iNaturalist dataset.

The Architecture:
1.   Five convolution layers with each layer followed by a
ReLU activation and a max pooling layer.
2.   One dense layer
3.   One output layer containing 10 neurons (1 for each of the 10 classes).
"""

!pip install wandb
import wandb
# Replace with your actual API key
api_key = "8f58df9a66485e9ea9149b8b599cb14eb71832dc"

# Login to Weights & Biases
wandb.login(key=api_key)

!pip install pytorch-lightning

"""Import essential libraries"""

import numpy as np


import random
import imageio
import os
import cv2
import glob
random.seed(42)

import torch
import torch.nn as nn
import torch.nn.functional as F
import pytorch_lightning as pl
from torchvision import transforms
from torch.utils.data import DataLoader, random_split
from torchvision.datasets import MNIST
from pytorch_lightning.callbacks import ModelCheckpoint
import wandb





"""Read the training and validation images"""

# Define the labels for the Simpsons characters we're detecting
class_names = {0:'Amphibia', 1:'Animalia', 2:'Arachnida',3: 'Aves',4: 'Fungi',
              5: 'Insecta', 6:'Mammalia', 7:'Mollusca', 8:'Plantae',9: 'Reptilia'}
num_classes = 10
img_size = 128
dir = 'inaturalist-dataset/train'

import random

# Load training data
X_train = []
y_train = []
for label, name in class_names.items():
   list_images = os.listdir(dir+'/'+name)
   for image_name in list_images:
       image = imageio.imread(dir+'/'+name+'/'+image_name)
       if np.ndim(image) == 3:
          X_train.append(cv2.resize(image, (img_size,img_size)))
          y_train.append(label)

"""Shuffle the images and then retain 10% as validation data"""

leng = np.shape(X_train)
arr = np.arange(leng[0])
np.random.shuffle(arr)
X_train_shuf = []
y_train_shuf = []
X_val_shuf = []
y_val_shuf = []

for i in range(leng[0]):
  if i <= 9000:
    X_train_shuf.append(X_train[arr[i]])
    y_train_shuf.append(y_train[arr[i]])
  else:
    X_val_shuf.append(X_train[arr[i]])
    y_val_shuf.append(y_train[arr[i]])

X_train = np.array(X_train_shuf)
y_train = np.array(y_train_shuf)
X_val = np.array(X_val_shuf)
y_val = np.array(y_val_shuf)

# Normalize the data
X_train = X_train/255.0
X_val = X_val/255.0

# One hot encode the labels
# y_train = np_utils.to_categorical(y_train, num_classes)
# y_val = np_utils.to_categorical(y_val, num_classes)
def one_hot_encode(labels, num_classes):
  """
  Custom function for one-hot encoding

  Args:
      labels: A tensor of integer labels.
      num_classes: The total number of possible categories.

  Returns:
      A tensor of one-hot encoded labels.
  """
  # y_onehot = torch.zeros((labels.size(0), num_classes))  # Create a zero tensor
  # y_onehot.scatter_(1, labels.view(-1, 1), 1)  # Scatter 1s at the corresponding indices
  y_onehot = torch.zeros((labels.size(0), num_classes))  # Create a zero tensor
  y_onehot.scatter_(1, labels.view(-1, 1).long(), 1)  # Scatter 1s at corresponding indices (cast to long)

  return y_onehot

# Convert NumPy arrays to PyTorch tensors
y_train_tensor = torch.from_numpy(y_train)
y_val_tensor = torch.from_numpy(y_val)

# One-hot encode the tensors
y_train = one_hot_encode(y_train_tensor, num_classes)
y_val = one_hot_encode(y_val_tensor, num_classes)

type(y_train)

leng = np.shape(X_train)
arr = np.arange(leng[0])
np.random.shuffle(arr)
X_train_shuf = []
y_train_shuf = []
X_val_shuf = []
y_val_shuf = []

for i in range(leng[0]):
  if i <= 9000:
    X_train_shuf.append(X_train[arr[i]])
    y_train_shuf.append(y_train[arr[i]])
  else:
    X_val_shuf.append(X_train[arr[i]])
    y_val_shuf.append(y_train[arr[i]])

X_train = np.array(X_train_shuf)
y_train = np.array(y_train_shuf)
X_val = np.array(X_val_shuf)
y_val = np.array(y_val_shuf)

# Normalize the data
X_train = X_train/255.0
X_val = X_val/255.0

# One hot encode the labels
# y_train = np_utils.to_categorical(y_train, num_classes)
# y_val = np_utils.to_categorical(y_val, num_classes)
def one_hot_encode(labels, num_classes):
  """
  Custom function for one-hot encoding

  Args:
      labels: A tensor of integer labels.
      num_classes: The total number of possible categories.

  Returns:
      A tensor of one-hot encoded labels.
  """
  # y_onehot = torch.zeros((labels.size(0), num_classes))  # Create a zero tensor
  # y_onehot.scatter_(1, labels.view(-1, 1), 1)  # Scatter 1s at the corresponding indices
  y_onehot = torch.zeros((labels.size(0), num_classes))  # Create a zero tensor
  y_onehot.scatter_(1, labels.view(-1, 1).long(), 1)  # Scatter 1s at corresponding indices (cast to long)

  return y_onehot

# Convert NumPy arrays to PyTorch tensors
y_train_tensor = torch.from_numpy(y_train)
y_val_tensor = torch.from_numpy(y_val)

# One-hot encode the tensors
y_train = one_hot_encode(y_train_tensor, num_classes)
y_val = one_hot_encode(y_val_tensor, num_classes)


# Define the labels for the Simpsons characters we're detecting
class_names = {0:'Amphibia', 1:'Animalia', 2:'Arachnida',3: 'Aves',4: 'Fungi',
              5: 'Insecta', 6:'Mammalia', 7:'Mollusca', 8:'Plantae',9: 'Reptilia'}
num_classes = 10
img_size = 128
dir = 'inaturalist-dataset/train'

import random

# Load training data
X_train = []
y_train = []
for label, name in class_names.items():
   list_images = os.listdir(dir+'/'+name)
   for image_name in list_images:
       image = imageio.imread(dir+'/'+name+'/'+image_name)
       if np.ndim(image) == 3:
          X_train.append(cv2.resize(image, (img_size,img_size)))
          y_train.append(label)

