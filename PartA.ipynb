{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/sainijagjit/CS6910-A2/blob/main/Part%20A/Assignment_2_iNaturalist.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "o4lwR6__7xmZ"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torchmetrics\n",
        "import pytorch_lightning as L\n",
        "import wandb\n",
        "from torch.utils.data import DataLoader, random_split, SubsetRandomSampler, Subset\n",
        "from sklearn.model_selection import train_test_split\n",
        "from torchvision.datasets import ImageFolder\n",
        "import torchvision.transforms as transforms\n",
        "import torchvision\n",
        "\n",
        "from pytorch_lightning.callbacks import EarlyStopping, Callback, ModelCheckpoint\n",
        "from pytorch_lightning.loggers import WandbLogger\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import pytorch_lightning as pl\n",
        "from torchmetrics import Accuracy\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "wandb.login(key=\"Your WandB api key\")\n",
        "wandb_project=\"DLASSIGN_2\"\n",
        "wandb_entity=\"ch22m009\"\n",
        "sweep_config = {\n",
        "  \"name\": \"DLA2\",\n",
        "  \"method\": \"random\",\n",
        "  'metric': {\n",
        "      'name': 'validation accuracy',\n",
        "      'goal': 'maximize'\n",
        "    },\n",
        "  \"parameters\": {\n",
        "        \"LearningRate\": {\n",
        "            \"values\": [1e-3,1e-4,1e-5]\n",
        "\n",
        "        },\n",
        "        \"Epochs\": {\n",
        "            \"values\": [10,15]\n",
        "\n",
        "        },\n",
        "        \"NumDenseNeurons\": {\n",
        "            \"values\": [512]\n",
        "\n",
        "        },\n",
        "        \"DropOut\":{\n",
        "            \"values\": [0,0.2,0.3,0.5]\n",
        "        },\n",
        "        \"Filters\": {\n",
        "            \"values\": [[32,64,128,256,512],[64,64,128,128,256],[32,64,64,128,128],[128,128,64,64,32],[128,128,128,128,128]]\n",
        "        },\n",
        "        \"ActiFun\": {\n",
        "            \"values\": [ \"ReLU\",\"GELU\",\"SELU\"]\n",
        "        },\n",
        "        \"BatchSize\": {\n",
        "            \"values\": [8,32,64,128]\n",
        "        },\n",
        "        \"BatchNorm\":{\n",
        "          \"values\": [True,False]\n",
        "        },\n",
        "        \"DataAugum\":{\n",
        "          \"values\": [True,False]\n",
        "        }\n",
        "    }\n",
        "}\n",
        "\n",
        "\n",
        "sweep_id = wandb.sweep(sweep_config, entity=wandb_entity, project=wandb_project)"
      ],
      "metadata": {
        "id": "XIpWnHvuszqn",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "40e38468-379e-4636-9dcb-0ca008d1aacd"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "wandb: Currently logged in as: ch22m009. Use `wandb login --relogin` to force relogin\n",
            "wandb: WARNING If you're specifying your api key in code, ensure this code is not shared publicly.\n",
            "wandb: WARNING Consider setting the WANDB_API_KEY environment variable, or running `wandb login` from the command line.\n",
            "wandb: Appending key for api.wandb.ai to your netrc file: C:\\Users\\Bhavik More\\.netrc\n",
            "500 response executing GraphQL.\n",
            "{\"errors\":[{\"message\":\"Post \\\"http://anaconda2.default.svc.cluster.local/validate\\\": read tcp 10.52.64.9:49466-\\u003e10.55.247.53:80: read: connection reset by peer\",\"path\":[\"upsertSweep\"]}],\"data\":{\"upsertSweep\":null}}\n",
            "wandb: ERROR Error while calling W&B API: Post \"http://anaconda2.default.svc.cluster.local/validate\": read tcp 10.52.64.9:49466->10.55.247.53:80: read: connection reset by peer (<Response [500]>)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Create sweep with ID: w0blnwlf\n",
            "Sweep URL: https://wandb.ai/ch22m009/DLASSIGN_2/sweeps/w0blnwlf\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Loading & Splitting Dataset**"
      ],
      "metadata": {
        "id": "QcWdSSs8nN6J"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class DataModule(L.LightningDataModule):\n",
        "    def __init__(self, BatchSize=64, DataAugum= True):\n",
        "        super().__init__()\n",
        "        self.BatchSize = BatchSize\n",
        "        self.DataAugum = DataAugum\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "        self.transform = transforms.Compose([\n",
        "              transforms.Resize(size=256),\n",
        "              transforms.CenterCrop(size=224),\n",
        "              transforms.ToTensor(),\n",
        "              transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
        "          ])\n",
        "\n",
        "        self.augmentation = transforms.Compose([\n",
        "              transforms.Resize(256),\n",
        "              transforms.CenterCrop(224),\n",
        "              transforms.ColorJitter(brightness=0.2, contrast=0.2, saturation=0.2, hue=0.1),\n",
        "              transforms.RandomAffine(degrees=30, translate=(0.1, 0.1), scale=(0.9, 1.1), shear=10),\n",
        "              transforms.RandomPerspective(distortion_scale=0.5, p=0.5),\n",
        "              transforms.RandomErasing(p=0.2, scale=(0.02, 0.33), ratio=(0.3, 3.3), value=0),\n",
        "              transforms.GaussianBlur(kernel_size=(5, 9), sigma=(0.1, 5)),\n",
        "              transforms.RandomGrayscale(p=0.1),\n",
        "              transforms.ToTensor(),\n",
        "              transforms.Normalize([0.5, 0.5, 0.5], [0.5, 0.5, 0.5])\n",
        "          ])\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "    def prepare_data(self):\n",
        "        self.train_dataset = ImageFolder(root='./nature_12K/inaturalist_12K/train')\n",
        "        self.test_dataset = ImageFolder(root='./nature_12K/inaturalist_12K/val')\n",
        "\n",
        "\n",
        "\n",
        "    def setup(self, stage=None):\n",
        "        dataset = ImageFolder(root='./nature_12K/inaturalist_12K/train')\n",
        "        test_dataset = ImageFolder(root='./nature_12K/inaturalist_12K/val', transform=self.transform)\n",
        "        train_size = int(0.8 * len(dataset))\n",
        "        val_size = len(dataset) - train_size\n",
        "        train_dataset, val_dataset = random_split(dataset, [train_size, val_size])\n",
        "        train_dataset.dataset.transform = self.augmentation\n",
        "        val_dataset.dataset.transform = self.transform\n",
        "        self.train_dataset, self.val_dataset, self.test_dataset = train_dataset, val_dataset, test_dataset\n",
        "\n",
        "    def train_dataloader(self):\n",
        "        return DataLoader(self.train_dataset, batch_size=self.BatchSize, shuffle=True, num_workers=1)\n",
        "\n",
        "\n",
        "    def val_dataloader(self):\n",
        "        return DataLoader(self.val_dataset, batch_size=self.BatchSize, num_workers=1)\n",
        "\n",
        "\n",
        "    def test_dataloader(self):\n",
        "        return DataLoader(self.test_dataset, batch_size=self.BatchSize, num_workers=1)\n",
        "\n"
      ],
      "metadata": {
        "id": "0b0lyT0QZnGg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "class Model1(pl.LightningModule):\n",
        "    def __init__(self,\n",
        "                 ActiFun='ReLU',\n",
        "                 Filters=[32,32,32,32,32],\n",
        "                 NumDenseNeurons=1024,\n",
        "                 LearningRate=0.01,\n",
        "                 BatchSize=64,\n",
        "                 DropOut=0.5,\n",
        "                 BatchNorm=True,\n",
        "                 loss_function='cross_entropy',\n",
        "                 optimizer='Adam'):\n",
        "        super().__init__()\n",
        "        self.save_hyperparameters()\n",
        "\n",
        "        self.BatchSize = BatchSize\n",
        "\n",
        "        # Define CNN layers\n",
        "        cnn_layers = []\n",
        "        for i in range(5):\n",
        "            in_channels = 3 if i == 0 else Filters[i - 1]\n",
        "            cnn_layers.extend([nn.Conv2d(in_channels, Filters[i], kernel_size=3),\n",
        "                               getattr(nn, ActiFun)()])\n",
        "            if BatchNorm:\n",
        "                cnn_layers.append(nn.BatchNorm2d(Filters[i], affine=True))\n",
        "            cnn_layers.append(nn.MaxPool2d(kernel_size=3, stride=2))\n",
        "\n",
        "        self.cnn_net = nn.Sequential(*cnn_layers)\n",
        "\n",
        "        # Calculate output size of CNN layers\n",
        "        n_sizes = self._get_conv_output((3, 224, 224))\n",
        "\n",
        "        # Define Dense layers\n",
        "        dnn_layers = [\n",
        "            nn.Flatten(),\n",
        "            nn.Linear(n_sizes, NumDenseNeurons)]\n",
        "        if DropOut:\n",
        "            dnn_layers.append(nn.Dropout(DropOut))\n",
        "        dnn_layers.extend([\n",
        "            getattr(nn, ActiFun)(),\n",
        "            nn.Linear(NumDenseNeurons, 10)])\n",
        "        self.dnn_net = nn.Sequential(*dnn_layers)\n",
        "\n",
        "        self.accuracy = Accuracy(task=\"multiclass\", num_classes=10)\n",
        "        self.loss_function = getattr(F, loss_function)\n",
        "        self.learning_rate = LearningRate\n",
        "        self.optimizer = optimizer\n",
        "\n",
        "    def _get_conv_output(self, shape):\n",
        "        input = torch.autograd.Variable(torch.rand(self.BatchSize, *shape))\n",
        "        output_feat = self._forward_features(input)\n",
        "        n_size = output_feat.data.view(self.BatchSize, -1).size(1)\n",
        "        return n_size\n",
        "\n",
        "    def _forward_features(self, x):\n",
        "        return self.cnn_net(x)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.cnn_net(x)\n",
        "        x = self.dnn_net(x)\n",
        "        return x\n",
        "\n",
        "    def training_step(self, batch, batch_idx):\n",
        "        loss, acc = self._common_step(batch)\n",
        "        self.log('Train_loss', loss, on_step=False, on_epoch=True, logger=True)\n",
        "        self.log('train_acc', acc, on_step=False, on_epoch=True, logger=True)\n",
        "        return loss\n",
        "\n",
        "    def validation_step(self, batch, batch_idx):\n",
        "        loss, acc = self._common_step(batch)\n",
        "        self.log('Validation_loss', loss, prog_bar=True, on_step=False, on_epoch=True, logger=True)\n",
        "        self.log('Validation_acc', acc, prog_bar=True, on_step=False, on_epoch=True, logger=True)\n",
        "        return loss\n",
        "\n",
        "    def test_step(self, batch, batch_idx):\n",
        "        loss, acc = self._common_step(batch)\n",
        "        self.log('Test_loss', loss, prog_bar=True, on_step=False, on_epoch=True, logger=True)\n",
        "        self.log('Test_acc', acc, prog_bar=True, on_step=False, on_epoch=True, logger=True)\n",
        "        return loss\n",
        "\n",
        "    def _common_step(self, batch):\n",
        "        inputs, target = batch\n",
        "        output = self.forward(inputs)\n",
        "        loss = self.loss_function(output, target)\n",
        "        acc = self.accuracy(output, target)\n",
        "        return loss, acc\n",
        "\n",
        "    def configure_optimizers(self):\n",
        "        return getattr(torch.optim, self.optimizer)(self.parameters(), lr=self.learning_rate)\n"
      ],
      "metadata": {
        "id": "77kf0t_Di_HY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "ZfkUkWRAha2s"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def train():\n",
        "\n",
        "    config_defaults = {\n",
        "        \"Filters\": [32,32,32,32,32],\n",
        "        \"BatchNorm\": True,\n",
        "        \"DataAugum\": True,\n",
        "        \"DropOut\":0.5,\n",
        "        \"LearningRate\": 1e-3,\n",
        "        \"ActiFun\": 'ReLU',\n",
        "        \"BatchSize\": 32,\n",
        "        \"Epochs\": 10,\n",
        "        \"NumDenseNeurons\": 512\n",
        "    }\n",
        "\n",
        "    wandb.init(config=config_defaults, magic=True)\n",
        "    config = wandb.config\n",
        "\n",
        "    name = \"_\".join([\"Eph\",str(config.Epochs),\n",
        "                 \"lr\", str(config.LearningRate),\n",
        "                 \"Acti\", config.ActiFun,\n",
        "                 \"#filt\", str(config.Filters),\n",
        "                 \"DAug\", str(config.DataAugum),\n",
        "                 \"DO\", str(config.DropOut),\n",
        "                 \"BNrm\", str(config.BatchNorm),\n",
        "                 \"#DnsN\",str(config.NumDenseNeurons),\n",
        "                 \"BSz\",str(config.BatchSize),\n",
        "\n",
        "                 ])\n",
        "\n",
        "    data1 = DataModule(config.BatchSize,config.DataAugum)\n",
        "    data1.prepare_data()\n",
        "    data1.setup()\n",
        "    model = Model1(config.ActiFun,config.Filters,config.NumDenseNeurons,config.LearningRate,config.BatchSize,config.DropOut,config.BatchNorm)\n",
        "    trainer = L.Trainer(max_epochs=config.Epochs)\n",
        "    trainer.fit(model, data1)\n"
      ],
      "metadata": {
        "id": "RI5elHjB9SVX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "wandb.agent(sweep_id, train, count=1, entity=wandb_entity, project=wandb_project)\n",
        "wandb.finish()"
      ],
      "metadata": {
        "id": "zGbEb3903ptK",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 922
        },
        "outputId": "a03678b5-0790-4e52-cb24-e3d8251c14b9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "wandb: Agent Starting Run: 5gobkgco with config:\n",
            "wandb: \tActiFun: GELU\n",
            "wandb: \tBatchNorm: False\n",
            "wandb: \tBatchSize: 32\n",
            "wandb: \tDataAugum: False\n",
            "wandb: \tDropOut: 0\n",
            "wandb: \tEpochs: 10\n",
            "wandb: \tFilters: [64, 64, 128, 128, 256]\n",
            "wandb: \tLearningRate: 1e-05\n",
            "wandb: \tNumDenseNeurons: 512\n",
            "wandb: WARNING wandb.init() arguments ignored because wandb magic has already been initialized\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Tracking run with wandb version 0.16.6"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Run data is saved locally in <code>C:\\Users\\Bhavik More\\Desktop\\test\\1\\wandb\\run-20240412_221326-5gobkgco</code>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Syncing run <strong><a href='https://wandb.ai/ch22m009/DLASSIGN_2/runs/5gobkgco' target=\"_blank\">gallant-sweep-1</a></strong> to <a href='https://wandb.ai/ch22m009/DLASSIGN_2' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>Sweep page: <a href='https://wandb.ai/ch22m009/DLASSIGN_2/sweeps/w0blnwlf' target=\"_blank\">https://wandb.ai/ch22m009/DLASSIGN_2/sweeps/w0blnwlf</a>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View project at <a href='https://wandb.ai/ch22m009/DLASSIGN_2' target=\"_blank\">https://wandb.ai/ch22m009/DLASSIGN_2</a>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View sweep at <a href='https://wandb.ai/ch22m009/DLASSIGN_2/sweeps/w0blnwlf' target=\"_blank\">https://wandb.ai/ch22m009/DLASSIGN_2/sweeps/w0blnwlf</a>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View run at <a href='https://wandb.ai/ch22m009/DLASSIGN_2/runs/5gobkgco' target=\"_blank\">https://wandb.ai/ch22m009/DLASSIGN_2/runs/5gobkgco</a>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Finishing last run (ID:5gobkgco) before initializing another..."
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View run <strong style=\"color:#cdcd00\">gallant-sweep-1</strong> at: <a href='https://wandb.ai/ch22m009/DLASSIGN_2/runs/5gobkgco' target=\"_blank\">https://wandb.ai/ch22m009/DLASSIGN_2/runs/5gobkgco</a><br/> View project at: <a href='https://wandb.ai/ch22m009/DLASSIGN_2' target=\"_blank\">https://wandb.ai/ch22m009/DLASSIGN_2</a><br/>Synced 4 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Find logs at: <code>.\\wandb\\run-20240412_221326-5gobkgco\\logs</code>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Successfully finished last run (ID:5gobkgco). Initializing new run:<br/>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Tracking run with wandb version 0.16.6"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Run data is saved locally in <code>C:\\Users\\Bhavik More\\Desktop\\test\\1\\wandb\\run-20240412_221327-5gobkgco</code>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Syncing run <strong><a href='https://wandb.ai/ch22m009/DLASSIGN_2/runs/5gobkgco' target=\"_blank\">gallant-sweep-1</a></strong> to <a href='https://wandb.ai/ch22m009/DLASSIGN_2' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>Sweep page: <a href='https://wandb.ai/ch22m009/DLASSIGN_2/sweeps/w0blnwlf' target=\"_blank\">https://wandb.ai/ch22m009/DLASSIGN_2/sweeps/w0blnwlf</a>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View project at <a href='https://wandb.ai/ch22m009/DLASSIGN_2' target=\"_blank\">https://wandb.ai/ch22m009/DLASSIGN_2</a>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View sweep at <a href='https://wandb.ai/ch22m009/DLASSIGN_2/sweeps/w0blnwlf' target=\"_blank\">https://wandb.ai/ch22m009/DLASSIGN_2/sweeps/w0blnwlf</a>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View run at <a href='https://wandb.ai/ch22m009/DLASSIGN_2/runs/5gobkgco' target=\"_blank\">https://wandb.ai/ch22m009/DLASSIGN_2/runs/5gobkgco</a>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "GPU available: True (cuda), used: True\n",
            "TPU available: False, using: 0 TPU cores\n",
            "IPU available: False, using: 0 IPUs\n",
            "HPU available: False, using: 0 HPUs\n",
            "You are using a CUDA device ('NVIDIA GeForce RTX 3050 Laptop GPU') that has Tensor Cores. To properly utilize them, you should set `torch.set_float32_matmul_precision('medium' | 'high')` which will trade-off precision for performance. For more details, read https://pytorch.org/docs/stable/generated/torch.set_float32_matmul_precision.html#torch.set_float32_matmul_precision\n",
            "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
            "\n",
            "  | Name     | Type               | Params\n",
            "------------------------------------------------\n",
            "0 | cnn_net  | Sequential         | 555 K \n",
            "1 | dnn_net  | Sequential         | 2.1 M \n",
            "2 | accuracy | MulticlassAccuracy | 0     \n",
            "------------------------------------------------\n",
            "2.7 M     Trainable params\n",
            "0         Non-trainable params\n",
            "2.7 M     Total params\n",
            "10.632    Total estimated model params size (MB)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\rSanity Checking: |                                                                               | 0/? [00:00<?, ?it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "C:\\Users\\Bhavik More\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\pytorch_lightning\\trainer\\connectors\\data_connector.py:436: Consider setting `persistent_workers=True` in 'val_dataloader' to speed up the dataloader worker initialization.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "C:\\Users\\Bhavik More\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\pytorch_lightning\\trainer\\connectors\\data_connector.py:436: Consider setting `persistent_workers=True` in 'train_dataloader' to speed up the dataloader worker initialization.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 0:  10%|█████▉                                                        | 24/250 [00:07<01:08,  3.32it/s, v_num=12]"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "Cu04f0-y5mAt"
      }
    }
  ]
}